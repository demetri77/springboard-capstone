---
title: "Banking Capstone - Machine Learning Applied"
author: "Demetri Lee"
date: "December 27, 2018"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(caret)
knitr::opts_chunk$set(echo = TRUE)
```

## Trying to predict the success of bank telemarketing

I'm trying to predict the success of telemarketing calls for a bank that's 
selling long-term deposits. A Portuguese retail bank was addressed, with data 
collected from 2008 to 2013, thus including the effects of the recent 
financial crisis of 2008. With 21 features available for analysis, I hope to 
derive knowledge for a model that would confirm how to better focus resources 
towards clients with a high chance of agreeing to registering for extra 
banking services. 

```{r}
bankfull_clean <- read_csv("bankfull_clean.csv", col_types = "ifffffffffiiiifdddddf")
# "iccccccccciiiicdddddc"

```

I will be treating this a supervised classification problem. While predicting 
whether a customer will subscribe to a new service, I need to find the main 
predictors while developing a model that best expressses a client's decision 
for subscribing. 

## Set Up Model Parameters

Let's start with partitioning the dataset into a training, validation, and 
test set.

```{r partition}
set.seed(13456)
# Split the full dataset into 80% and 20% partitions
TrainingValidationIndex <- createDataPartition(y=bankfull_clean$subscribed, p=0.80, list=FALSE)
training_validation <- bankfull_clean[TrainingValidationIndex,]

# Split the main 80% into a Training (75%) and Validation (25%) set
trainIndex <- createDataPartition(training_validation$subscribed, p=0.75, list=FALSE)
training <- training_validation[trainIndex,]
validation <- training_validation[-trainIndex,]

# Original 20% kept aside as Test Data
testData  <- bankfull_clean[-TrainingValidationIndex,]

#trControl(sampling)
control <- trainControl(method = "cv", number = 2, classProbs = TRUE, verboseIter = TRUE)
```

## Logistic Regression with CARET

Develop a model with the training data. 

```{r logReg}
# develop a model
set.seed(7)
glm_model_full <- train(subscribed ~ ., data=training, method="glm", na.action=na.omit)
```


What can we conclude from the logistic regression model? 

```{r}
summary(glm_model_full) # results with entire variable set
```

Let's apply our model to the validation set.

```{r}
glm_predict_full <- predict(glm_model_full, newdata=validation)
```


Here is a confusion matrix, with the results expressing accuracy, sensitivity, 
and specificity.
```{r}
glm_confMatrix <- caret::confusionMatrix(glm_predict_full, validation$subscribed, mode="everything") 

glm_confMatrix
# use metric parameter; F1 or Kappa

# investigate further parameters (eg F1/accuracy score)
# Precision = TP / (TP + FP)
# Recall = TP / (TP + FN)
```

**Comparing results of Logistic Regression model:**

* Kappa = 0.4672
* F1 = 0.9497016

## Random Forest with CARET

Develop a model with training data.

```{r rdmForest}
# play with smaller # of rf while playing/testing
set.seed(7)
rf_model <- caret::train(subscribed~., data=training, method="rf",
                         trControl=trainControl(method="cv", number=10))

summary(rf_model)
```


Apply the Random Forest model to the Validation set.

```{r}
rf_prediction <- predict(rf_model, newdata=validation)
```


Review the Confusion Matrix for the Random Forest model.

```{r}
rf_confMatrix <- caret::confusionMatrix(rf_prediction, validation$subscribed, mode="everything")

rf_confMatrix
```

**Comparing results of Random Forest:**

5 FOLDS:

* Kappa = 0.4871
* F1 = 0.9455

10 FOLDS:

* Kappa = 0.5145
* F1 = 0.9481


```{r}
write_csv(bankfull_clean, path="bankfull_ml.csv", col_names=TRUE)
```

